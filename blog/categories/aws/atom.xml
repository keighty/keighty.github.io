<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Aws | keighty]]></title>
  <link href="http://www.katieleonard.ca/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://www.katieleonard.ca/"/>
  <updated>2015-09-13T13:10:20-07:00</updated>
  <id>http://www.katieleonard.ca/</id>
  <author>
    <name><![CDATA[katie leonard]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Uploading Images From Node and Angular to S3]]></title>
    <link href="http://www.katieleonard.ca/blog/2015/uploading-images-from-node-slash-angular-to-s3/"/>
    <updated>2015-02-24T00:00:00-08:00</updated>
    <id>http://www.katieleonard.ca/blog/2015/uploading-images-from-node-slash-angular-to-s3</id>
    <content type="html"><![CDATA[<p>Amazon Web Services allow you to do everything, so it is hard to figure out how to do anything. I have a node/angular/mongo stack running on Heroku, and want to use Amazon to store images. I was delighted to stumble across <a href="https://devcenter.heroku.com/articles/s3-upload-node"><em>Direct to S3 Uploads in Node.js</em></a>, written by Will Webberly for the Heroku Dev Center blog.
Following his <a href="https://github.com/flyingsparx/NodeDirectUploader">example</a>, I was able to upload images directly from the browser to S3, saving my app server a whole lot of work.</p>

<!--more-->


<p>In the example, when a user selects a file for upload, the browser asks the node server for a temporary signed request. The server replies with a signed url, and the browser can send the data directly to Amazon. TADA &mdash; Almost. With a few exceptions. One of the prerequisites is that you know how to set up an S3 bucket and IAM user with the correct access controls.</p>

<h4>Setting the S3 stage</h4>

<p>When S3 receives a request it must verify that the requester has the proper permissions &mdash; both at the account level, as well as at the bucket level. With a seemingly infinite number of services available through Amazon, I found that I had to aggregate information from a few different sources.</p>

<ol>
<li>Create a bucket

<ul>
<li>See <a href="http://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html">this Amazon tutorial</a> for how to create a bucket.</li>
</ul>
</li>
<li>Create a user

<ul>
<li>See <a href="http://docs.aws.amazon.com/IAM/latest/UserGuide/Using_SettingUpUser.html#Using_CreateUser_console">this Amazon tutorial</a> for creating an IAM User.</li>
<li>Be sure to record the generated <code>Access Key ID</code> and <code>Secret Access Key</code>. They will act as user name and password for accessing your bucket.</li>
</ul>
</li>
<li>Grant the IAM User access to S3

<ul>
<li>In the IAM User section of the AWS Management Console, select <code>Attach Policy</code>, and add <code>AmazonS3FullAccess</code> from the list
{% img /images/IAM_Management_Console.png %}</li>
</ul>
</li>
<li>Grant the IAM User access to the bucket

<ul>
<li>Use <a href="http://awspolicygen.s3.amazonaws.com/policygen.html">this Amazon tool</a> to help you generate an Access Control Policy. The key pieces you need for the policy generator are the AWS Principle (the user you created), which you enter in the format <code>arn:aws:iam::&lt;your_account_number&gt;:&lt;IAM_user_name&gt;</code>, and the Resource (the bucket you created), which you enter in the format <code>arn:aws:s3:::&lt;your_bucket_name&gt;/*</code>.</li>
</ul>
</li>
</ol>


<p>{% codeblock Your access control policy should look like this example: %}
{
  &ldquo;Version&rdquo;:&ldquo;2012-10-17&rdquo;,
  &ldquo;Id&rdquo;: &ldquo;Policy1234567890123&rdquo;,
  &ldquo;Statement&rdquo;:[{</p>

<pre><code>"Sid":"Stmt123456789",
"Effect":"Allow",
"Principal": {
        "AWS": "arn:aws:iam::111122223333:specialUser"
},
"Action":[
  "s3:PutObject",
  "s3:DeleteObject",
  "s3:GetObject"
],
"Resource":"arn:aws:s3:::examplebucket/*"
</code></pre>

<p>  }]
}
{% endcodeblock %}</p>

<p>In case you get lost, here is <a href="http://docs.aws.amazon.com/AmazonS3/latest/dev/how-s3-evaluates-access-control.html">one more invaluable Amazon tutorial</a>.</p>

<h4>Angular client side</h4>

<p>Using an angular app on the client side is also a slight deviation from the Webberly tutorial. Angular <a href="https://github.com/angular/angular.js/issues/1375">does not support</a> an <code>ng-change</code> binding on file input elements, but there is a <a href="http://stackoverflow.com/a/17923521">workaround</a>:</p>

<p>{% codeblock lang:html %}
<input type="file" class="form-control btn" id="image" onchange="angular.element(this).scope().s3Upload(this)">
{% endcodeblock %}</p>

<p>Additionally, instead of adding the upload function as plain javascript in your html template, add the <code>s3Upload</code> function onto the <code>$scope</code> in your controller.</p>

<p>{% codeblock lang:javascript %}
$scope.s3Upload = function(){
  var status_elem = document.getElementById(&ldquo;status&rdquo;);
  var url_elem = document.getElementById(&ldquo;image_url&rdquo;);
  var preview_elem = document.getElementById(&ldquo;preview&rdquo;);
  var s3upload = new S3Upload({</p>

<pre><code>  s3_object_name: showTitleUrl(),  // upload object with a custom name
  file_dom_selector: 'image',
  s3_sign_put_url: '/sign_s3',
  onProgress: function(percent, message) {
      status_elem.innerHTML = 'Upload progress: ' + percent + '% ' + message;
  },
  onFinishS3Put: function(public_url) {
      status_elem.innerHTML = 'Upload completed. Uploaded to: '+ public_url;
      url_elem.value = public_url;
      preview_elem.innerHTML = '&lt;img src="'+ public_url +'" style="width:300px;" /&gt;';
  },
  onError: function(status) {
      status_elem.innerHTML = 'Upload error: ' + status;
  }
</code></pre>

<p>  });
};
{% endcodeblock %}</p>

<p>Note the diff on line 6 &mdash; taking a peek into the <a href="https://github.com/flyingsparx/NodeDirectUploader/blob/master/public/javascripts/s3upload.js#L23-L29">S3Upload source</a>, you can set a custom file name by passing a <code>s3_object_name</code> option. Otherwise, every object will be named <code>default_name</code>.</p>

<p>{% codeblock lang:javascript %}
$scope.s3_upload = function(){
  &hellip;
  var s3upload = new S3Upload({</p>

<pre><code>s3_object_name: showTitleUrl(),  // upload object with a custom name
file_dom_selector: 'image',
s3_sign_put_url: '/sign_s3',
</code></pre>

<p>  &hellip;
}</p>

<p>function showTitleUrl() {
  var title = $scope.show.title.split(&lsquo; &rsquo;).join(&lsquo;_&rsquo;);
  var dateId = Date.now().toString();
  return dateId + title;
}
{% endcodeblock %}</p>

<h4>Add <code>image</code> to your schema</h4>

<p>The last stumbling block I encountered was saving the image url into mongo. The image would upload and appear just fine, but wouldn&rsquo;t persist the url as a property of the object. I had forgotten to add the image to my mongo Schema &mdash; the schema acts a bit like a whitelist for saving attributes through mongoose into mongo. Adding the <a href="https://github.com/keighty/virtualplaybill2/blob/ad04bcde8ce00c5ce349f43d2e0cc50549c59df7/models/posts_model.js#L11">imageUrl to the schema</a> solved all my woes.</p>

<p>If you are trying to accomplish something similar, Heroku has articles on <a href="https://devcenter.heroku.com/articles/s3">uploading directly to S3</a> using many different stacks.</p>
]]></content>
  </entry>
  
</feed>
